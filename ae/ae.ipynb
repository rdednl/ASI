{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h1>Advanced Statistical Inference - Assessed Exercise</h1>\n",
    "<h2>Daniele Reda</h2>\n",
    "</div>\n",
    "<h3>Note on color codings</h3>\n",
    "<div class=\"label label-warning\">Yellow</div> is used for titles and subtitles\n",
    "<div class=\"label label-default\">Transparent</div> is used for formulas, explanations and informations\n",
    "<div class=\"label label-info\">Blue</div> is used to write the questions asked by the assessed exercise\n",
    "<div class=\"label label-success\">Green</div> is used for the answers to the questions\n",
    "<div class=\"label label-danger\">Red</div> is for to-dos (hopefully you shouldn't see any of these)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Introduction and Instruction</h3>\n",
    "<br>\n",
    "In this work you will analyze the MNIST and CIFAR10 datasets available to download from:\n",
    "<br>\n",
    "<ul>\n",
    "<li>http://yann.lecun.com/exdb/mnist/\n",
    "<li>https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "</ul>\n",
    "<br>\n",
    "Listed below are various exercises to undertake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Download the MNIST and CIFAR10 datasets and import them.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist, cifar10\n",
    "\n",
    "(mnist_train_data, mnist_train_label), (mnist_test_data, mnist_test_label) = mnist.load_data()\n",
    "(cifar10_train_data, cifar10_train_label), (cifar10_test_data, cifar10_test_label) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Comment on the distribution of class labels and the dimensionality of the input and how these may affect the analysis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import functools\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(221)\n",
    "plt.imshow(cifar10_test_data[np.random.randint(0, len(cifar10_test_data))])\n",
    "plt.subplot(222)\n",
    "plt.imshow(cifar10_test_data[np.random.randint(0, len(cifar10_test_data))])\n",
    "plt.subplot(223)\n",
    "plt.imshow(mnist_test_data[np.random.randint(0, len(mnist_test_data))])\n",
    "plt.subplot(224)\n",
    "plt.imshow(mnist_test_data[np.random.randint(0, len(mnist_test_data))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "TODO comment figures, plot distribution of labels\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h3>Classification</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Implement the Naïve Bayes classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naïve Bayes classifier is a very simple probabilistic classifier based on Bayes rule:\n",
    "<br><br>\n",
    "\\begin{equation}\n",
    "P(\\ t_{new}=k \\ \\vert \\ \\mathbf{X},\\mathbf{t},\\mathbf{x}_{new}\\ )\n",
    "= \\frac {P(\\ \\mathbf{x}_{new} \\ \\vert \\ t_{new}=k, \\mathbf{X},\\mathbf{t} \\ ) \\ P( \\ t_{new}=k \\ )}\n",
    "        {\\sum_jP(\\ \\mathbf{x}_{new} \\ \\vert \\ t_{new} = j, \\mathbf{X},\\mathbf{t} \\ ) \\ P( \\ t_{new}=k \\ )}\n",
    "\\end{equation}\n",
    "<br><br>\n",
    "given that:\n",
    "<ul>\n",
    "<li>$\\mathbf{X}$ is the data of our training set\n",
    "<li>$\\mathbf{t}$ are the labels of our training set\n",
    "<li>$\\mathbf{x}_{new}$ is the sample we want to classify\n",
    "<li>$t_{new}$ is the class of our sample we want to evaluate\n",
    "</ul>\n",
    "<br>\n",
    "We define the elements of the Bayes rule as:\n",
    "<ul>\n",
    "<li><b>Posterior</b>: $P(\\ t_{new}=k \\ \\vert \\ \\mathbf{X},\\mathbf{t},\\mathbf{x}_{new}\\ )$\n",
    "<ul><li>It's the probability of $\\mathbf{x}_{new}$ belonging to class $k$ given the training set $\\mathbf{X}$ and its labels $\\mathbf{t}$</ul>\n",
    "<li><b>Likelihood</b>: $P(\\ \\mathbf{x}_{new} \\ \\vert \\ t_{new}=k, \\mathbf{X},\\mathbf{t} \\ )$\n",
    "<ul><li>It is a density (<b>not</b> a probability) telling how likely it is that, given that the label of the element is $k$, we are able to see an element like $\\mathbf{x}_{new}$</ul>\n",
    "<li><b>Prior</b>: $P( \\ t_{new}=k \\ )$\n",
    "<ul><li>It is the probability of finding the label $k$ without any observations on the data.</ul>\n",
    "<li><b>Marginal likelihood</b>: $\\sum_jP(\\ \\mathbf{x}_{new} \\ \\vert \\ t_{new} = j, \\mathbf{X},\\mathbf{t} \\ ) \\ P( \\ t_{new}=k \\ )$\n",
    "<ul><li>Normalisation constant.</ul>\n",
    "</ul>\n",
    "<br>\n",
    "The <i>likelihood</i> for a label $k$ is defined as:\n",
    "\\begin{equation}\n",
    "\\prod\\limits_{d=1}^{K}\\mathcal{N}(\\mu_{kd}, \\ \\sigma^2_{kd})\n",
    "\\end{equation}\n",
    "where $\\mu_{kd}$ and $\\sigma^2_{kd}$ are:\n",
    "\\begin{align*}\n",
    "\\mu_{kd} =& \\ \\frac{1}{N_k} \\ \\sum\\limits_{n:t_n=k} x_{nd} \\\\\n",
    "\\sigma^2_{kd} =& \\ \\frac{1}{N_k} \\ \\sum\\limits_{n:t_n=k} (x_{nd} - \\mu_{kd})^2\n",
    "\\end{align*}\n",
    "<br>\n",
    "and so it becomes, for mnist, a product of 784 gaussians. <i>Why 784?</i> Because mnist images are 28x28 and when we flat the matrix we get a vector of 784 elements and we have to build a gaussian for each pixel that represents the distribution of the color of that pixel for that label. The same happens for cifar where each image is a 32x32 matrix with 3 channels and so it gets fatten into a 32x32x3=3072 numpy array.\n",
    "<br><br>\n",
    "The <i>prior</i> for a label $k$ is defined as:\n",
    "\\begin{equation}\n",
    "\\frac{nr. \\ of \\ elements \\ of \\ label \\ k}{total \\ nr. \\ of \\ elements}\n",
    "\\end{equation}\n",
    "<br><br>\n",
    "Below is the code for computing naïve Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior(data, size):\n",
    "    return len(data)/size\n",
    "    \n",
    "def get_means_and_variances(data):\n",
    "    return (np.array(data).mean(axis=0), np.array(data).var(axis=0)+1e-3)\n",
    "\n",
    "def get_likelihood(means, variances, sample):\n",
    "    def gauss(mean, var, sample_d):\n",
    "        return np.exp(-(sample_d-mean)/(2*var)) / np.sqrt(2*np.pi*var)\n",
    "    return functools.reduce(lambda x,y: np.float128(x)*np.float128(y), \\\n",
    "                            [gauss(a, b, c) for a,b,c in zip(means, variances, sample)])\n",
    "\n",
    "\n",
    "def get_marginal_likelihood(likelihoods, priors):\n",
    "    return np.sum([x*y for x,y in zip(likelihoods, priors)])\n",
    "\n",
    "def get_posterior(likelihood, prior, marginal_likelihood):\n",
    "    print(likelihood, prior, marginal_likelihood)\n",
    "    return likelihood*prior/marginal_likelihood\n",
    "\n",
    "def predict(data, labels, samples, norm=None, mnist=True):\n",
    "    train_size = len(data)\n",
    "    test_size = len(samples)\n",
    "        \n",
    "    data = data.reshape(train_size, -1)\n",
    "    samples = samples.reshape(test_size, -1)\n",
    "\n",
    "    if norm:\n",
    "        data = data/norm\n",
    "        samples = samples/norm\n",
    "        \n",
    "    dict_per_label = {k:[] for k in np.unique(labels)}\n",
    "    for _ in np.arange(train_size):\n",
    "        if mnist is True:\n",
    "            dict_per_label[labels[_]].append(data[_])\n",
    "        else:\n",
    "            dict_per_label[labels[_][0]].append(data[_])\n",
    "                \n",
    "    priors = [get_prior(dict_per_label[k], train_size) for k in np.unique(labels)]\n",
    "    #print priors\n",
    "    \n",
    "    means_and_variances = [get_means_and_variances(dict_per_label[k]) for k in np.unique(labels)]\n",
    "    predictions = []\n",
    "    \n",
    "    for sample in samples:\n",
    "        likelihoods = [get_likelihood(_[0], _[1], sample) for _ in means_and_variances]\n",
    "        marginal_likelihood = get_marginal_likelihood(likelihoods, priors)\n",
    "        probabilities_k = [get_posterior(likelihoods[k], priors[k], marginal_likelihood) for k in np.unique(labels)]\n",
    "        #print(probabilities_k)\n",
    "        predictions.append(np.argmax(probabilities_k))\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Describe a positive and a negative feature of the classifier for these tasks.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Describe any data pre-processing that you suggest for this data and your classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "TODO explain zero frequency problem (why we summed one everywhere)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Describe a positive and a negative feature of the classifier for these tasks.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Apply your classifier to the two given datasets.\n",
    "<br>\n",
    "Make sure your optimization is clearly commented.\n",
    "<br>\n",
    "Use classification accuracy and test log-likelihood as your figures of merit.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "predictions = predict(mnist_train_data, mnist_train_label, mnist_test_data, norm=255)\n",
    "print(time.time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7150\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for k in np.arange(len(mnist_test_data)):\n",
    "    if predictions[k] == mnist_test_label[k]:\n",
    "        correct += 1\n",
    "        \n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before (1, 28, 28) 1\n",
      "shape after (1, 784) 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(mnist_train_data, mnist_train_label, mnist_test_data[3:4], norm=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.1 0.0\n",
      "0.0 0.1 0.0\n",
      "0.0 0.1 0.0\n",
      "0.0 0.1 0.0\n",
      "0.0 0.1 0.0\n",
      "0.0 0.1 0.0\n",
      "0.0 0.1 0.0\n",
      "0.0 0.1 0.0\n",
      "0.0 0.1 0.0\n",
      "0.0 0.1 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel/__main__.py:18: RuntimeWarning: invalid value encountered in longdouble_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(cifar10_train_data, cifar10_train_label, cifar10_test_data[2000:2001], mnist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Display the confusion matrix on the test data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Discuss the performance, compare them against a classifier that outputs random class labels, and suggest ways in which performance could be improved.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h3>Linear Regression</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Implement Bayesian linear regression.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Treat class labels as continuous and apply regression to the training data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Produce a scatter plot showing the predictions versus the true targets for the test set and compute the m ",
    " ean squared error on the test set.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Suggest a way to discretize predictions and display the confusion matrix on the test data and report accuracy.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Discuss regression performance with respect to classification performance.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Describe one limitation of using regression for this particular task.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h3>Bonus question</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The state-of-the-art in these image classification problems suggests that convolutional layers in convolutional neural networks yield most of the improvements compared to standard neural networks. The reason is that they are capable of modeling spatial patterns through the hierarchical analysis of patches of images. Propose and implement ways to exploit patch information in the Naïve Bayes classifier or linear regression. A couple of suggestions are: (i) apply Naïve Bayes classification to the output of convolutional layer in the LeNet architecture (ii) construct the Naïve Bayes classifier by calculating patch-specific statistics and extend this by stacking multiple of these\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
